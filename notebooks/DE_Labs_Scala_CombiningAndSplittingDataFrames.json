{"paragraphs":[{"text":"%md\n# About This Lab\n**Objective:** Learn how to combine and split DataFrames\n**File locations:** s3://shared-edu/sci/\n**Successful outcome:**\n**Before you begin:**\n**Related lessons:** Working with DataFrames\n\nCopyright © 2010–2021 Cloudera. All rights reserved.\nNot to be reproduced or shared without prior written consent from Cloudera.\n\n---","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:39:26+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104971_1542347664","id":"20171105-200834_1116095891","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:39:26+0000","dateFinished":"2022-01-24T16:39:26+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:119385"},{"text":"%md\n## Overview\n\nIn this module we demonstrate how to combine and split DataFrames.\n\n## Combining and Splitting DataFrames\n\n* Spark SQL supports the usual database-style joins:\n    * Cross join\n    * Inner join\n    * Left semi join\n    * Left anti join\n    * Left outer join\n    * Right outer join\n    * Full outer join\n\n* Joins are expensive in the big-data world\n    * Perform joins early in the process\n    * Amortize the cost over many use cases\n\n* Spark SQL supports the following set operations:\n    * Union\n    * Intersection\n    * Subtraction\n\n* Spark SQL provides a method to split a DataFrame into random subsets","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:39:26+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104972_-1309756508","id":"20210609-222433_1574519092","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:39:27+0000","dateFinished":"2022-01-24T16:39:27+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119386"},{"text":"%md\n# Setup\n---","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:39:27+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104972_1693020849","id":"20181114-164229_902436001","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:39:28+0000","dateFinished":"2022-01-24T16:39:28+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119387"},{"title":"Required for Kerberos operations","text":"%sh\n\necho $PASS | kinit $USER","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:39:28+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh","title":true,"tableHide":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042178687_-1061701261","id":"20220124-163618_719925397","dateCreated":"2022-01-24T16:36:18+0000","dateStarted":"2022-01-24T16:39:28+0000","dateFinished":"2022-01-24T16:39:28+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119388"},{"title":"Setup the data context","text":"%sh\n\nrm -rf data\nmkdir -p data\naws s3 cp --recursive s3://shared-edu/sci/duocar/raw data/raw\naws s3 cp --recursive s3://shared-edu/sci/duocar/clean data/clean\naws s3 cp --recursive s3://shared-edu/sci/duocar/joined data/joined\nhdfs dfs -rm -r duocar\nhdfs dfs -mkdir -p duocar\nhdfs dfs -put -f data duocar","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:39:29+0000","config":{"colWidth":12,"fontSize":9,"enabled":true,"results":{},"editorSetting":{"language":"sh","editOnDblClick":false,"completionKey":"TAB","completionSupport":false},"editorMode":"ace/mode/sh","title":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042198786_535810771","id":"20220124-163638_1059867163","dateCreated":"2022-01-24T16:36:38+0000","dateStarted":"2022-01-24T16:39:29+0000","dateFinished":"2022-01-24T16:39:44+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119389"},{"text":"%md\n# Lesson\n---","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:39:44+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104973_845007344","id":"20210609-150445_381117564","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:39:45+0000","dateFinished":"2022-01-24T16:39:45+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119390"},{"text":"%md\n## Joining DataFrames","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:39:46+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104973_-678221733","id":"20210609-231102_1173405065","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:39:46+0000","dateFinished":"2022-01-24T16:39:46+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119391"},{"title":"We will use the following DataFrames to demonstrate joins","text":"%spark\n\nval scientists = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"duocar/data/raw/data_scientists/\")\nscientists.show()\n\nval offices = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"duocar/data/raw/offices/\")\noffices.show()","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:41:39+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104974_407087188","id":"20210609-231136_1486159156","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:41:40+0000","dateFinished":"2022-01-24T16:41:41+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119392"},{"title":"Cross join","text":"%spark\n\n// Use the `crossJoin` DataFrame method to join every row in the left (`scientists`) DataFrame with every row in the right (`offices`) DataFrame:\nscientists.crossJoin(offices).show()\n","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:41:41+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104975_-1550326744","id":"20210609-231416_373015015","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:41:42+0000","dateFinished":"2022-01-24T16:41:43+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119393"},{"title":"Warning","text":"%md\nThis can result in very big DataFrames!","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:41:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104975_-266454898","id":"20210609-231614_1055557420","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:41:44+0000","dateFinished":"2022-01-24T16:41:44+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119394"},{"title":"Note","text":"%md\nColumns with the same name are not renamed.\nThis is called the *Cartesian product* of the two DataFrames.","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:41:44+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104976_-1615883455","id":"20210609-231636_1254576650","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:41:45+0000","dateFinished":"2022-01-24T16:41:45+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119395"},{"title":"Inner join","text":"%spark\n\n// Use the `join` DataFrame method with different values of the `how` argument to perform other types of joins\n\n// Use a join expression and the value `inner` to return only those rows for which the join expression is true:\nscientists.join(offices, scientists(\"office_id\") === offices(\"office_id\"), \"inner\").show()\n\n// This gives us a list of data scientists associated with an office and the corresponding office information.\n\n// Since the join key has the same name on both DataFrames, we can simplify the join as follows:\nscientists.join(offices, \"office_id\").show()\n","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:41:45+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104977_529681829","id":"20210609-231821_1865619957","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:41:46+0000","dateFinished":"2022-01-24T16:41:47+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119396"},{"title":"Left semi join","text":"%spark\n\n// Use the value `left_semi` to return the rows in the left DataFrame that match rows in the right DataFrame:\nscientists.join(offices, scientists(\"office_id\") === offices(\"office_id\"), \"left_semi\").show\n\n// This gives us a list of data scientists associated with an office.","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:41:47+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104977_2094449233","id":"20210609-232653_529939127","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:41:48+0000","dateFinished":"2022-01-24T16:41:49+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119397"},{"title":"Left anti join","text":"%spark\n\n// Use the value `left_anti` to return the rows in the left DataFrame that do not match rows in the right DataFrame:\n\nscientists.join(offices, scientists(\"office_id\") === offices(\"office_id\"), \"left_anti\").show\n\n// This gives us a list of data scientists not associated with an office.","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:41:49+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104978_-1567982460","id":"20210609-232830_1046047309","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:41:50+0000","dateFinished":"2022-01-24T16:41:51+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119398"},{"title":"Note","text":"%md\nYou can think of the left semi and left anti joins as special types of filters.","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:41:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104979_-1305777013","id":"20210609-232929_1918392793","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:41:52+0000","dateFinished":"2022-01-24T16:41:52+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119399"},{"title":"Left outer join","text":"%spark\n\n// Use the value `left` or `left_outer` to return every row in the left DataFrame with or without matching rows in the right DataFrame:\nscientists.join(offices, scientists(\"office_id\") === offices(\"office_id\"), \"left_outer\").show\n\n// This gives us a list of data scientists with or without an office.","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:41:52+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104981_-514989882","id":"20210609-232928_637649899","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:41:53+0000","dateFinished":"2022-01-24T16:41:54+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119400"},{"title":"Right outer join","text":"%spark\n\n// Use the value `right` or `right_outer` to return every row in the right\n// DataFrame with or without matching rows in the left DataFrame:\n\nscientists.join(offices, scientists(\"office_id\") === offices(\"office_id\"), \"right_outer\").show\n\n// This gives us a list of offices with or without a data scientist.","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:41:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104981_-1689294373","id":"20210609-233132_835639263","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:41:55+0000","dateFinished":"2022-01-24T16:41:56+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119401"},{"title":"Note","text":"%md\nThe Paris office has two data scientists.","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:41:56+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104982_-1869237588","id":"20210609-233310_197367113","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:41:57+0000","dateFinished":"2022-01-24T16:41:57+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119402"},{"title":"Full outer join","text":"%spark\n\n// Use the value `full`, `outer`, or `full_outer` to return the union of the left outer and right outer joins (with duplicates removed):\nscientists.join(offices, scientists(\"office_id\") === offices(\"office_id\"), \"full_outer\").show\n\n// This gives us a list of all data scientists whether or not they have an office and all offices whether or not they have any data scientists.","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:41:57+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104982_1621357129","id":"20210609-233410_1919989150","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:41:58+0000","dateFinished":"2022-01-24T16:42:00+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119403"},{"text":"%md\n### Example: Joining the DuoCar data\n\nLet us join the driver, rider, and review data with the ride data.","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:00+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104983_285798761","id":"20210609-233554_1146424900","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:01+0000","dateFinished":"2022-01-24T16:42:01+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119404"},{"title":"Read the clean data from HDFS","text":"%spark\n\nval rides = spark.read.parquet(\"duocar/data/clean/rides/\")\nval drivers = spark.read.parquet(\"duocar/data/clean/drivers/\")\nval riders = spark.read.parquet(\"duocar/data/clean/riders/\")\nval reviews = spark.read.parquet(\"duocar/data/clean/ride_reviews/\")","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:01+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104984_650515461","id":"20210609-233639_1852715423","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:02+0000","dateFinished":"2022-01-24T16:42:03+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119405"},{"title":"Since we want all the ride data, we will use a sequence of left outer joins","text":"%spark\n\nval joined = (rides\n  .join(drivers, rides(\"driver_id\") === drivers(\"id\"), \"left_outer\")\n  .join(riders, rides(\"rider_id\") === riders(\"id\"), \"left_outer\")\n  .join(reviews, rides(\"id\") === reviews(\"ride_id\"), \"left_outer\"))\njoined.printSchema()","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:03+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104984_267282774","id":"20210609-233827_952416184","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:04+0000","dateFinished":"2022-01-24T16:42:05+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119406"},{"title":"Note","text":"%md\nWe probably want to rename some columns before joining the data and remove the duplicate ID columns after joining the data to make this DataFrame  more usable.","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:05+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104985_-1398199906","id":"20210609-233930_2039257022","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:07+0000","dateFinished":"2022-01-24T16:42:07+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119407"},{"title":"For example, see the `joined` data in the DuoCar data repository","text":"%spark\n\nspark.read.parquet(\"duocar/data/joined/\").printSchema","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:07+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104986_-576496459","id":"20210609-233913_91627979","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:08+0000","dateFinished":"2022-01-24T16:42:09+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119408"},{"text":"%md\n\n## Applying set operations to DataFrames\n\nSpark SQL provides the following DataFrame methods that implement set operations:\n* `union`\n* `intersect`\n* `except`","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:09+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104986_-1295925164","id":"20210609-234159_1381331125","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:10+0000","dateFinished":"2022-01-24T16:42:10+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119409"},{"title":" Use the `union` method to get the union of rows in two DataFrames with similar schema","text":"%spark\n\nval driver_names = drivers.select(\"first_name\")\ndriver_names.count()\n\nval rider_names = riders.select(\"first_name\")\nrider_names.count()\n\nval names_union = driver_names.union(rider_names).orderBy(\"first_name\")\nnames_union.count()\nnames_union.show()","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:10+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104987_-1997439240","id":"20210609-234321_1548059875","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:11+0000","dateFinished":"2022-01-24T16:42:13+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119410"},{"title":"Note that `union` does not remove duplicates. Use the `distinct` method to remove duplicates","text":"%spark\n\nval names_distinct = names_union.distinct()\nnames_distinct.count()\nnames_distinct.show()","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:13+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104988_-822790076","id":"20210609-234423_2092462479","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:14+0000","dateFinished":"2022-01-24T16:42:16+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119411"},{"title":"Use the `intersect` method to return rows that exist in both DataFrames","text":"%spark\n\nval name_intersect = driver_names.intersect(rider_names).orderBy(\"first_name\")\nname_intersect.count()\nname_intersect.show()","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:16+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104988_-1840840918","id":"20210609-234548_1163824754","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:17+0000","dateFinished":"2022-01-24T16:42:20+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119412"},{"title":"Use the `except` method to return rows in the left DataFrame that do not exist in the right DataFrame","text":"%spark\n\nval names_subtract = driver_names.except(rider_names).orderBy(\"first_name\")\nnames_subtract.count()\nnames_subtract.show()","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:20+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104989_-87460931","id":"20210609-234546_925355223","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:21+0000","dateFinished":"2022-01-24T16:42:24+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119413"},{"text":"%md\n ## Splitting a DataFrame","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:24+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104990_-493669801","id":"20210609-234757_657885115","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:25+0000","dateFinished":"2022-01-24T16:42:25+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119414"},{"title":"Use the `randomSplit` DataFrame method to split a DataFrame into random subsets","text":"%spark\n\nriders.count()\nval Array(train, validate, test) = riders.randomSplit(weights=Array(0.6, 0.2, 0.2))\n(train.count(), validate.count(), test.count())\n\n// Use the `seed` argument to ensure replicability:\nval Array(train, validate, test) = riders.randomSplit(Array(0.6, 0.2, 0.2), seed=12345)\n(train.count(), validate.count(), test.count())\n\n// If the proportions do not add up to one, then Spark will normalize the values:\nval Array(train, validate, test) = riders.randomSplit(Array(60.0, 20.0, 20.0), seed=12345)\n(train.count(), validate.count(), test.count())","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:25+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104991_824850964","id":"20210609-234752_1390806088","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:26+0000","dateFinished":"2022-01-24T16:42:29+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119415"},{"title":"Note","text":"%md\nThe weights must be doubles.\nThe same seed will result in the same random split.","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:29+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104992_979001983","id":"20210609-234752_348698865","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:31+0000","dateFinished":"2022-01-24T16:42:31+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119416"},{"text":"%md\n# Lab\n---","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:31+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104993_-1413830630","id":"20210609-150527_79851234","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:31+0000","dateFinished":"2022-01-24T16:42:31+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119417"},{"title":"1 - Join the `rides` DataFrame with the `reviews` DataFrame.  Keep only those rides that have a review","text":"%spark\n","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:32+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104993_699458055","id":"20210609-235614_801953798","dateCreated":"2022-01-24T16:35:04+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119418"},{"title":"2 - How many drivers have not provided a ride?","text":"%spark\n","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:33+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104994_-560420896","id":"20210609-235732_713641342","dateCreated":"2022-01-24T16:35:04+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119419"},{"text":"%md\n# Result\n**You have now:** learned how to combine and split DataFrames.\n\n---","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:34+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104995_811544424","id":"20181119-142716_792318228","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:34+0000","dateFinished":"2022-01-24T16:42:34+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119420"},{"text":"%md\n# Solution\n---","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:34+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104996_1926484961","id":"20171113-155535_1769142099","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:35+0000","dateFinished":"2022-01-24T16:42:35+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119421"},{"title":"1 - Join the `rides` DataFrame with the `reviews` DataFrame.  Keep only those rides that have a review","text":"%spark\n\n// Count the number of reviews before the join:\nreviews.count()\n\n// Perform a right outer join:\nval rides_with_reviews = rides.join(reviews, rides(\"id\") === reviews(\"ride_id\"), \"right_outer\")\n\n// Count the number of reviews after the join:\nrides_with_reviews.count()\n\n// Print the schema:\nrides_with_reviews.printSchema()\n","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:35+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104997_-762052497","id":"20210609-235838_715916045","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:36+0000","dateFinished":"2022-01-24T16:42:37+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119422"},{"title":"2 - How many drivers have not provided a ride?","text":"%spark\n\n// Get the driver IDs from `drivers` DataFrame:\nval id_from_drivers = drivers.select(\"id\")\n\n// Get the driver IDs from `rides` DataFrame:\nval id_from_rides = rides.select(\"driver_id\").withColumnRenamed(\"driver_id\", \"id\")\n\n// Find lazy drivers using a left anti join:\nval lazy_drivers1 = id_from_drivers.join(id_from_rides, id_from_drivers(\"id\") === id_from_rides(\"id\"), \"left_anti\")\nlazy_drivers1.count()\nlazy_drivers1.orderBy(\"id\").show(5)\n\n// Find lazy drivers using a subtraction:\nval lazy_drivers2 = id_from_drivers.except(id_from_rides)\nlazy_drivers2.count()\nlazy_drivers2.orderBy(\"id\").show(5)","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:37+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB","completionSupport":true},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042104998_-1573713966","id":"20210609-235831_219349651","dateCreated":"2022-01-24T16:35:04+0000","dateStarted":"2022-01-24T16:42:38+0000","dateFinished":"2022-01-24T16:42:43+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119423"},{"title":"References","text":"%md\n\n* [Spark Python API - crossJoin DataFrame method](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.crossJoin.html#pyspark.sql.DataFrame.crossJoin)\n\n* [Spark Python API - join DataFrame method](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.join.html#pyspark.sql.DataFrame.join)\n\n* [Spark Python API - union DataFrame method](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.union.html#pyspark.sql.DataFrame.union)\n\n* [Spark Python API - intersect DataFrame method](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.intersect.html#pyspark.sql.DataFrame.intersect)\n\n* [Spark Python API - subtract DataFrame method](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.subtract.html#pyspark.sql.DataFrame.subtract)\n\n* [Spark Python API - randomSplit DataFrame method](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.randomSplit.html#pyspark.sql.DataFrame.randomSplit)\n","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042105000_39761941","id":"20210609-235023_710325981","dateCreated":"2022-01-24T16:35:05+0000","dateStarted":"2022-01-24T16:42:44+0000","dateFinished":"2022-01-24T16:42:44+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119424"},{"title":"Additional resources","text":"%md\nWe hope you've enjoyed this lab. Below are additional resources that you should find useful:\n\n1. [Cloudera Tutorials](http://cloudera.com/tutorials.html) are your natural next step where you can explore Spark in more depth.\n2. [Cloudera Community](https://community.cloudera.com) is a great resource for questions and answers on Spark, Data Analytics/Science, and many more Big Data topics.\n3. [Apache Spark Documentation](https://spark.apache.org/documentation.html) - official Spark documentation.\n4. [Apache Zeppelin Project Home Page](https://zeppelin.apache.org) - official Zeppelin web site.","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:44+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":10,"editorMode":"ace/mode/markdown","fontSize":9,"editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042105001_-322484515","id":"20181116-135131_93712280","dateCreated":"2022-01-24T16:35:05+0000","dateStarted":"2022-01-24T16:42:45+0000","dateFinished":"2022-01-24T16:42:45+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119425"},{"text":"%angular\n</br>\n</br>\n</br>\n</br>\n<center>\n<a href=\"https://www.cloudera.com/about/training/courses.html\">\n  <img src=\"https://www.cloudera.com/content/dam/www/marketing/media-kit/logo-assets/cloudera_logo_darkorange.png\" alt=\"Cloudera University\" style=\"width:280px;height:40px;border:0;\" align=\"middle\">\n</a>\n</center>\n</br>\n</br>","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:45+0000","config":{"tableHide":false,"editorSetting":{"language":"scala","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":2,"editorMode":"ace/mode/undefined","fontSize":9,"editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042105001_-1005341107","id":"20200110-154537_1406191376","dateCreated":"2022-01-24T16:35:05+0000","dateStarted":"2022-01-24T16:42:46+0000","dateFinished":"2022-01-24T16:42:46+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119426"},{"text":"%angular\n","user":"freynalddeveuwest1","dateUpdated":"2022-01-24T16:42:46+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":true,"completionKey":"TAB","completionSupport":false},"colWidth":12,"editorMode":"ace/mode/undefined","fontSize":9,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1643042105002_-272438142","id":"20200110-162013_302547143","dateCreated":"2022-01-24T16:35:05+0000","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:119427"}],"name":"DE/Labs/Scala/CombiningAndSplittingDataFrames","id":"2GU3NWK2N","noteParams":{},"noteForms":{},"angularObjects":{"md:shared_process":[],"angular:shared_process":[],"sh:shared_process":[],"livy:shared_process":[]},"config":{"isZeppelinNotebookCronEnable":false,"looknfeel":"default","personalizedMode":"false"},"info":{}}